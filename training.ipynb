{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module) :\n",
    "    def __init__(self, n, m):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(in_features=100, out_features=256), nn.ReLU())\n",
    "        self.l2 = nn.Sequential(nn.Linear(in_features=256, out_features=512), nn.ReLU())\n",
    "        self.l3 = nn.Sequential(nn.Linear(in_features=512, out_features=1024), nn.ReLU())\n",
    "        self.output = nn.Sequential(nn.Linear(in_features=1024, out_features=n*m), nn.Tanh())\n",
    "    def forward(self, x) :\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN() :\n",
    "    def __init__(self, n, m) :\n",
    "        self.generator = Generator(n, m)\n",
    "        self.discriminator = models.resnet50(pretrained=True)\n",
    "        self.discriminator.fc = nn.Linear(in_features=512, out_features=2)\n",
    "        self.discriminator = self.discriminator.to('cpu')\n",
    "        self.discr_criterion = torch.nn.BCELoss()\n",
    "        self.discr_optimizer = torch.optim.SGD(self.discriminator.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "        self.gen_criterion = torch.nn.BCELoss()\n",
    "        self.gen_optimizer = torch.optim.SGD(self.discriminator.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    def learning_step(self, x) :\n",
    "        self.evolution.append(self.generator(self.test_noises))\n",
    "        z = torch.randn(x.shape[0], 1, 100)\n",
    "        fakes = self.generator(z)\n",
    "        fake_classes = self.discriminator(fakes)\n",
    "        real_classes = self.discriminator(x)\n",
    "        fake_loss = self.discr_criterion(fake_classes, torch.ones[x.shape[0]])\n",
    "        real_loss = self.discr_criterion(real_classes, torch.zeros[x.shape[0]])\n",
    "        full_loss = fake_loss + real_loss\n",
    "        full_loss.backward()\n",
    "        self.discr_optimizer.step()\n",
    "        self.generator.zero_grad()\n",
    "        gen_loss = self.gen__criterion(fake_classes, torch.zeros[x.shape[0]])\n",
    "        gen_loss.backward()\n",
    "        self.gen_optimizer.step()\n",
    "        return gen_loss, full_loss\n",
    "    \n",
    "    def fit(self, file_path, epochs_number) :\n",
    "        trans = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.RandomResizedCrop(32),\n",
    "                                        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "        trans_data = datasets.ImageFolder(file_path, trans)\n",
    "        dataloader = DataLoader(trans_data, batch_size=128, shuffle=True, num_workers=4)\n",
    "        history = {'generator' : [], 'discriminator' : []}\n",
    "        for epoch in range(epochs_number) :\n",
    "            losses = {'generator' : [], 'discriminator' : []}\n",
    "            for i, data in enumerate(dataloader, 0) :\n",
    "                x, _ = data\n",
    "                gen_loss, full_loss = self.learning_step(x)\n",
    "                losses['generator'].append(float(gen_loss))\n",
    "                losses['discriminator'].append(float(full_loss))\n",
    "                history['generator'].append(float(gen_loss))\n",
    "                history['discriminator'].append(float(full_loss))\n",
    "            avg_gen_loss = np.mean(losses['generator'])\n",
    "            avg_discr_loss = np.mean(losses['discriminator'])\n",
    "            print(\"Epoch {} / {}: Generator Loss = {:.3f}, Discriminator Loss = {:.3f}\".format(epoch+1, epochs_number, avg_gen_loss, avg_discr_loss))\n",
    "        return history\n",
    "    \n",
    "    def predict(self, n) :\n",
    "        z = torch.randn(n, 1, 100)\n",
    "        fakes = self.generator(z)\n",
    "        for i, tensor in enumerate(fakes) :\n",
    "            image = tensor.clone().detach().numpy()\n",
    "            img = Image.fromarray(image, 'RGB')\n",
    "            img.save(f'image_{i+1}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAN(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit('dataset', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
